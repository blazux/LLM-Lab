{
  "policy_checkpoint": "checkpoints/best_model.pt",
  "datasets": [
    {
      "name": "OpenAssistant/oasst1",
      "split": "train",
      "weight": 2.0
    },
    {
      "name": "HuggingFaceH4/ultrachat_200k",
      "split": "train_sft",
      "weight": 1.0
    }
  ],
  "validation_splits": ["validation", "val", "test"],
  "batch_size": 4,
  "gradient_accumulation_steps": 16,
  "max_steps": 5000,
  "learning_rate": 5e-6,
  "weight_decay": 0.01,
  "max_grad_norm": 1.0,
  "optimizer": "adamw",
  "adamw_beta1": 0.9,
  "adamw_beta2": 0.999,
  "adamw_eps": 1e-8,
  "muon_momentum": 0.95,
  "muon_nesterov": true,
  "lion_beta1": 0.9,
  "lion_beta2": 0.99,
  "sophia_beta1": 0.965,
  "sophia_beta2": 0.999,
  "sophia_rho": 0.04,
  "scheduler": "cosine",
  "warmup_steps": 100,
  "log_every": 10,
  "save_every": 500,
  "eval_every": 250,
  "eval_steps": 50,
  "save_best_only": true,
  "output_dir": "sft_checkpoints",
  "use_lora": false,
  "lora_preset": "minimal",
  "lora_target_modules": null,
  "lora_r": 8,
  "lora_alpha": 16,
  "lora_dropout": 0.05,
  "max_seq_len": null
}
